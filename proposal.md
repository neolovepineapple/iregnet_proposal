# iregnet on CRAN

## Project Info

**Project title:** iregnet on CRAN

**URL of project idea page:** [https://github.com/rstats-gsoc/gsoc2019/wiki/iregnet-on-CRAN](https://github.com/rstats-gsoc/gsoc2019/wiki/iregnet-on-CRAN)


## Bio of Student

I am Ao Ni, currently a senior student who major in Applied Statistics at Sun Yat-sen University, China. After graduation, I will study for a master's degree in Computer Science at Johns Hopkins University. I code in Python, C++, R and Swift. During my undergraduate years, I have worked on many Computer Science or Statistics related project, including the development of R Package. 

Survival Analysis is one of my favorite course, that's why I am so excited about this project. Beyond Courses, I have researched on ARIC (The Atherosclerosis Risk in Communities Study). This dataset provide detailed medical history data of over ten thousand of participants, which could be transformed into the interval of certain disease (e.g. peripheral arterial disease). I believe iregnet is the perfect tool to handle this kind of datasets. Equiped with strong coding skills and Statistical knowledge, I would love to work on this project and bring iregnet on CRAN.



## Contact Information

**Student name:** Ao Ni

**Student postal address:** Room 302, Building 3, Hupojiawan Residential Zone, Changxing County, Zhejiang Province, China

**Telephone:** +86 155-2138-9969

**Email:** neo.aoni@gmail.com 

**Other communications channels:** live:neolovepineapple (Skype)





## Student Affiliation 

**Institution:** School of Mathematics, Sun Yat-sen University

**Program:** B.S in Applied Statistics

**Stage of completion:** Graduate at June, 2019

**Contact to verify:** 

Haiyan Lin,      
Teaching Secretary at School of Mathematics, Sun Yat-sen University          
email: mcslhy@mail.sysu.edu.cn



## Schedule Conflicts

I will commit my whole summer to GSoC. There will be no other internships or projects during this summer.

## Mentors
**Mentor names:**

* Toby Dylan Hocking
* Anuj Khare


**Mentor emails:**

* Toby Dylan Hocking (tdhock5@gmail.com)
* Anuj Khare (khareanuj18@gmail.com)

**Have you been in touch with the mentors? When and how?**



## Coding Plan and Method

### Implement a cross validation method on iregnet

In this section, my goal is to implement a cross-validation function to fit an interval regression (i.e. iregnet) by optimizing the lambda parameter. This function calls iregnet repeatedly according to the number of flods. Then a set of validation errors are calculated corresponding to a list of lambda values, which were either manually specified or generated by algorithm. The best lambda will be choosen based on different criterion.

#### Method

This part focus on the theoratical aspect of the implementation. The keys when select the best lambda value by cross validation are error functions and selecting criterion. 

After fitting the model on training set and makeing prediction on validation set, the validation errors are calculated by error functions. In this proposal I propose two error functions. 



-Log Likelihood

iregnet use coordinate descent solver to maximize the log likelihood function. Thus, it is a natural idea to use log likelihood to measure the performance in cross validation. The calculation of log likelihood depends on the type of ground truth. Take the example of gaussian distribution, if the left and right bound of interval are the same, the likelihood function is a density function for a normal distribution with mean equal to the prediction and standard deviation equal to the scale. The metrics is the return value when ground truth is passed as a argument to this density function. Following graph illustrate this idea.

![](mdfiles/density_plot.png)



For the most part, the ground truth is not a exact value but an interval, the metrics is given by the area between the left bound and right bound under the same density curve. See following graph for detail.

![](mdfiles/probability_plot.png)

 
-Outside Prediction

Outside prediction means the percentage of predicted values which are outside the corresponding label/interval. We need a explainable metric when we train a model and want to test the performace on a testing set. Unluckily, log likelihood is not able to fulfill the requirement. Outside prediction is a better metric because it intuitivly presents the performance of model. Thus, use this metric in a cross validation can result in a higher performance model.

```r
#Outside Prediction
op.error<- function(gt.left, gt.right, pred){
  n <- length(pred)
  err <- (pred>gt.right) || (pred<gt.left)
  return(error/n)
}
```



Selecting criterion specifies how the regularization parameter is chosen during the internal cross-validation loop. For the most part there are two way to choose parameter.

-min

First take the mean of cross validation errors for each lambda, then choose the lambda that result in the minimum error. It tends to yield the least test error.


-1sd

take the most regularized model which is within one standard deviation of that minimum, this model is typically a bit less accurate, but much less, complex, so better if you want to interpret the coefficients.




#### Details for Implementation

I will start my implementation with a R function ```iregnetCV()```



```r

iregnetCV <- function(
### This function use cross-validation to fit accelerated failure time models 
### failure time models. This function calls iregnet repeatedly to find the best 
### lambda.
  x,
### Input matrix of covariates with dimension n_obs * n_vars, with nvars ≥ 2.
### Sparse matrices are not supported.
  y,
### Response variable. It can take two forms
  n.folds = 5,
### The number of folds. 
  flod.id = sample(rep(1:n.folds,length.out = nrow(x))),
### Index for each validation set.
  family = "gaussian",
### The distribution to fit. 
  alpha = 1,
### Elastic net mixing parameter, with 0 ≤ α ≤ 1. 
  lambda = NULL,
### Vector containing the path of decreasing regularization parameter lambda values.
  num_lambda = 100,
### The number of lambda values calculated by the function. Ignored if lambda
### is supplied by the user. 
  loss.func = "loglik",
### After fitting the model on training set and makeing prediction on validation set,
### the validation errors are calculated by error functions. specify loss function 
### using 'loss.func'
###   'loglik': The calculation of log likelihood depends on the type of ground truth. 
###   Take the example of gaussian distribution, if the left and right bound of 
###   interval are the same, the likelihood function is a density function for a normal
###   distribution with mean equal to the prediction and standard deviation equal to 
###   the scale. The metrics is the return value when ground truth is passed as a 
###   argument to this density function. For the most part, the ground truth is not 
###   a exact value but an interval, the metrics is given by the area between the left 
###   bound and right bound under the same density curve. See following graph for detail.
###   'outpred': Outside prediction means the percentage of predicted values which are 
###   outside the corresponding label/interval.
  type = "min",
### This argument specifies how the regularization parameter is chosen 
### during the internal cross-validation loop.
###   'min': Take the mean of cross validation errors for each lambda,
###   then choose the lambda that result in the minimum error. It tends 
###   to yield the least test error.
###   '1sd': Take the most regularized model which is within one standard 
###   deviation of that minimum, this model is typically a bit less accurate, 
###   but much less, complex, so better if you want to interpret the coefficients.
intercept = TRUE,
standardize = TRUE,
scale_init = NA,
maxiter = 1e3,
threshold = 1e-4,
unreg_sol = TRUE,
eps_lambda = ifelse(ncol(x)<nrow(x),0.0001,0.1),
debug = FALSE
){
  ...
}
```





### Write a qualified docs to pass all CRAN checks.


### Implementation of Vignette




















